#' Read JACUSA2 result file
#'
#' \code{read_result()} Reads data that was generated by JACUSA2 and creates a JACUSA2 result object.
#'
#' @param file String that represents the filename of the JACUSA2 output.
#' @param showProgress Boolean indicates if progress should be monitored.
#'
#' @export
read_result <- function(file, showProgress = TRUE) {
  # pre process file
  # parse comments ^(#|##) to determine result/method type and number of conditions
  con <- file(file, "r")
  conditions <- 0
  skip_lines <- 0
  header_names <- NULL
  # possible result/method types: unknown, call-pileup, rt-arrest, lrt-arrest
  # type <- .UNKNOWN_METHOD_TYPE
  while (TRUE) {
    line = readLines(con, n = 1)
    # quit reading: nothing to read or first no header line 
    if (length(line) == 0 || length(grep("^#", line)) == 0) {
      break
    }
    # count header lines to ignore
    skip_lines <- skip_lines + 1
    
    if (length(grep("^#contig", line)) > 0) {
      # try to guess result/method by header line
      type <- guess_file_type(line)
      # type will be vali or .guess_file_type throw error
      
      # parse and store header
      # fix header: #contig -> contig
      header_names <- sub("^#", "", line);
      header_names <- unlist(strsplit(header_names, "\t"))
      
      # guess number of conditions  
      conditions <- guess_conditions(type, header_names)
    }
  }
  # finished pre-processing
  close(con)
  
  # check that a header could be parsed
  if (is.null(header_names)) {
    stop("No header line for file: ", file)
  }
  
  # check that conditions could be guessed
  if (conditions < 1) {
    stop("Conditions could not be guessed for file: ", file)
  }
  
  # read data
  data <- data.table::fread(file, 
                            skip = skip_lines, 
                            sep = "\t",
                            header = FALSE, 
                            showProgress = showProgress)  
  colnames(data) <- header_names
  
  # create result depending on determined method type 
  result <- create_result(type, conditions, data)
  
  result
}

# Create result for type and conditions from data 
create_result <- function(type, conditions, data) {
  info <- data %>% dplyr::select(contig, start, end, strand, info)
  data$info <- NULL
  result <- NULL
  if(type == CALL_PILEUP_METHOD_TYPE) {
    result <- create_bases(data, conditions, CALL_PILEUP_COLUMN)
  } else if (type == RT_ARREST_METHOD_TYPE) {
    result <- create_bases(data, conditions, c(RT_ARREST_COLUMN, RT_THROUGH_COLUMN))
    result[["primary"]] <- TRUE
  } else if (type == LRT_ARREST_METHOD_TYPE) {
    result <- create_bases(data, conditions, c(LRT_ARREST_COLUMN, LRT_THROUGH_COLUMN))
    result[["primary"]] <- TRUE
  } else {
    stop("Unknown type: ", type)
  }
  attributes(result)[[ATTRIBUTE_TYPE]] <- type
  
  # add base call
  bc <- apply(result[, paste0("bc_", BASES)], 1, function(x) { 
    paste0(BASES[x > 0], collapse = "")
  })
  # add allele count
  result$allele_count <- nchar(bc)
  result$bc <- bc
  
  # only parse deletions, if there are any
  if (any(grep("^deletion", info$info))) {
      result <- merge(
      result, 
      process_deletion(conditions, info), 
      by = c("contig", "start", "end", "strand", "condition", "replicate"),
      all.x = TRUE
    )
  }
  
  # make factors
  result$condition <- as.factor(result$condition)
  result$replicate <- as.factor(result$replicate)
  
  dplyr::as_tibble(result)
}

# helper function to extract deletion info(s)
process_deletion <- function(conditions, info) {
  df <- info %>% 
    tidyr::separate_rows(info, INFO_COLUMN, sep = ";") %>% 
    tidyr::separate(
      col = !! INFO_COLUMN, 
      into = c("key", "value"), 
      sep = "=", fill = "right") %>% 
    dplyr::filter(key != EMPTY) %>%
    tidyr::spread(key, value) %>% 
    tidyr::gather(
      key = "deletion_sample", 
      value = "deletion_counts", 
      dplyr::matches("^deletions")) %>%
    tidyr::extract(
      deletion_sample, 
      c("condition", "replicate"), 
      regex = paste0("^deletions([0-9]{", nchar(conditions), "})([0-9]+)"), 
      remove = TRUE, convert = TRUE) %>%
    tidyr::separate(deletion_counts, paste0("deletion_", c("reads", "coverage")), 
                    sep = ",", remove = TRUE, convert = TRUE)
  
  df$deletion_pvalue <- as.numeric(df$deletion_pvalue)
  df$deletion_score <- as.numeric(df$deletion_score)
  
  df
}

# helper functions to create data container to hold data
create_bases <- function(df, conditions, column) {
  # convert wide to long
  r <- tidyr::gather(
    df, 
    sample, bases, 
    lapply(column, dplyr::starts_with) %>% unlist()
  )
  
  # extract condition and replicate
  r <- tidyr::extract(r, sample, c("base_type", "condition", "replicate"), 
                      regex = paste0("^(", 
                                     paste0(column, collapse = "|"), 
                                     ")([0-9]{", 
                                     nchar(conditions), 
                                     "})([0-9]+)"), 
                      remove = TRUE, convert = TRUE)
  i <- r$bases == EMPTY
  r$bases[i] <- paste0(rep(0, length(BASES)), collapse = ",")
  # extract base call columns from "," encoded strings
  # convert string: "0,10,2,0" to new columns: bc_A = 0, bc_C = 10, bc_G = 2, bc_T = 0
  r <- tidyr::separate(r, bases, paste0("bc_", BASES), 
                       sep = ",", remove = TRUE, convert = TRUE)
  
  if (length(unique(r$base_type)) == 1) {
    r$base_type <- "total"
  } else {
    r <- r %>% 
      group_by_site("arrest_pos", condition, replicate) %>%
      dplyr::mutate(base_type = "total", bc_A = sum(bc_A), bc_C = sum(bc_C), bc_G = sum(bc_G), bc_T = sum(bc_T)) %>%
      dplyr::distinct() %>%
      dplyr::ungroup() %>%
      rbind(r)
  }
  
  r
}

#' Read multiple related JACUSA2 results
#' 
#' TODO
#' 
#' @param files vector of files
#' @param meta_conditions vector of string describing each
#' @return combined JACUSA2 result object
#'
#' @export
read_results <- function(files, meta_conditions) {
  stopifnot(length(files) == length(meta_conditions))

  types <- SUPPORTED_METHOD_TYPES
  # read all files  
  l <- mapply(function(file, meta_condition) {
    result <- read_result(file)
    result$meta_condition <- as.factor(meta_condition)

    # this makes sure that all files have the same JACUSA2 type
    attr <- attributes(result)
    type <- attr[[ATTRIBUTE_TYPE]]
    if (! type %in% types) {
      stop("All files must have the same type. File: ", file, " has type: ", type)
    }
    types <- type

    result
  }, files, meta_conditions)
  
  # combine read files
  results <- dplyr::bind_rows(l)
  results$meta_condition <- as.factor(results$meta_condition)
  
  results
}

#' @noRd
check_jacusa_method <- function(result, types = SUPPORTED_METHOD_TYPES) {
  if (is.null(attributes(result))) {
    stop("result does not have any attributes")
  }
  
  attr <- attributes(result)
  if (! ATTRIBUTE_TYPE %in% names(attr)) {
    stop("result has not been created by read_result or is of unknown type")
  }
  
  type <- attr[[ATTRIBUTE_TYPE]]
  if (! type %in% types) {
    stop("result has an unsupported type: ", type)
  }
  
  TRUE
}
