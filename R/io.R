#' Read JACUSA2 result file
#'
#' \code{read_result()} Reads data that was generated by JACUSA2 and creates a JACUSA2 result object.
#'
#' @param file String that represents the filename of the JACUSA2 output.
#' @param showProgress Boolean indicates if progress should be monitored.
#'
#' @export
read_result <- function(file, showProgress = TRUE) {
  # pre process file
  # parse comments ^(#|##) to determine result/method type and number of conditions
  con <- file(file, "r")
  conditions <- 0
  skip_lines <- 0
  header_names <- NULL
  # possible result/method types: unknown, call-pileup, rt-arrest, lrt-arrest
  # type <- .UNKNOWN_METHOD_TYPE
  while (TRUE) {
    line = readLines(con, n = 1)
    # quit reading: nothing to read or first no header line 
    if (length(line) == 0 || length(grep("^#", line)) == 0) {
      break
    }
    # count header lines to ignore
    skip_lines <- skip_lines + 1

    if (length(grep("^#contig", line)) > 0) {
      # try to guess result/method by header line
      type <- .guess_file_type(line)
      # type will be vali or .guess_file_type throw error

      # parse and store header
      # fix header: #contig -> contig
      header_names <- sub("^#", "", line);
      header_names <- unlist(strsplit(header_names, "\t"))
      
      # guess number of conditions  
      conditions <- .guess_conditions(type, header_names)
    }
  }
  # finished pre-processing
  close(con)
  
  # check that a header could be parsed
  if (is.null(header_names)) {
    stop("No header line for file: ", file)
  }

  # check that conditions could be guessed
  if (conditions < 1) {
    stop("Conditions could not be guessed for file: ", file)
  }
  
  # read data
  data <- data.table::fread(file, 
                            skip = skip_lines, 
                            sep = "\t",
                            header = FALSE, 
                            showProgress = showProgress)  
  colnames(data) <- header_names

  # create combined position id from genomic coordinates
  data$id <- dplyr::group_indices(
    data, contig, start, end, strand
  )

  # create result depending on determined method type 
  result <- .create_result(type, conditions, data)
  
  result
}

# Create result for type and conditions from data 
.create_result <- function(type, conditions, data) {
  info <- data %>% dplyr::select(id, info)
  data$info <- NULL
  result <- NULL
  if(type == .CALL_PILEUP_METHOD_TYPE) {
    result <- .create_bases(data, conditions, .CALL_PILEUP_COLUMN)
  } else if (type == .RT_ARREST_METHOD_TYPE) {
    result <- .create_bases(data, conditions, c(.RT_ARREST_COLUMN, .RT_THROUGH_COLUMN))
  } else if (type == .LRT_ARREST_METHOD_TYPE) {
    result <- .create_bases(data, conditions, c(.LRT_ARREST_COLUMN, .LRT_THROUGH_COLUMN))
  } else {
    stop("Unknown type: ", type)
  }
  result$type <- type

  # add base call
  bc <- apply(result[, paste0("bc_", .BASES)], 1, function(x) { 
    paste0(.BASES[x > 0], collapse = "")
  })
  # add allele count
  result$allele_count <- nchar(bc)
  result$bc <- bc

  # only parse deletions, if there are any
  # FIXME id different
  #if (any(grep("^deletion", info$info))) {
  #    result <- merge(
  #    result, 
  #    .process_deletion(conditions, info), 
  #    by = c("id", "condition", "replicate"),
  #    all.x = TRUE
  #  )
  #}

  # make factors
  result$condition <- as.factor(result$condition)
  result$replicate <- as.factor(result$replicate)
  
  result
}

# helper function to extract deletion info(s)
.process_deletion <- function(conditions, info) {
  df <- info %>% 
    tidyr::separate_rows(info, .INFO_COLUMN, sep = ";") %>% 
    tidyr::separate(
      col = !! .INFO_COLUMN, 
      into = c("key", "value"), 
      sep = "=", fill = "right") %>% 
    dplyr::filter(key != .EMPTY) %>%
    tidyr::spread(key, value) %>% 
    tidyr::gather(
      key = "deletion_sample", 
      value = "deletion_counts", 
      dplyr::matches("^deletions")) %>%
    tidyr::extract(
      deletion_sample, 
      c("condition", "replicate"), 
      regex = paste0("^deletions([0-9]{", nchar(conditions), "})([0-9]+)"), 
      remove = TRUE, convert = TRUE) %>%
    tidyr::separate(deletion_counts, paste0("deletion_", c("reads", "coverage")), 
                         sep = ",", remove = TRUE, convert = TRUE)

  df$deletion_pvalue <- as.numeric(df$deletion_pvalue)
  df$deletion_score <- as.numeric(df$deletion_score)

  df
}

# helper functions to create data container to hold data
.create_bases <- function(df, conditions, column) {
  # convert wide to long
  r <- tidyr::gather(
    df, 
    sample, bases, 
    lapply(column, dplyr::starts_with) %>% unlist()
  )

  # extract condition and replicate
  r <- tidyr::extract(r, sample, c("base_type", "condition", "replicate"), 
                      regex = paste0("^(", 
                                     paste0(column, collapse = "|"), 
                                     ")([0-9]{", 
                                     nchar(conditions), 
                                     "})([0-9]+)"), 
                      remove = TRUE, convert = TRUE)
  i <- r$bases == .EMPTY
  r$bases[i] <- paste0(rep(0, length(JACUSA2helper:::.BASES)), collapse = ",")
  # extract base call columns from "," encoded strings
  # convert string: "0,10,2,0" to new columns: bc_A = 0, bc_C = 10, bc_G = 2, bc_T = 0
  r <- tidyr::separate(r, bases, paste0("bc_", .BASES), 
                       sep = ",", remove = TRUE, convert = TRUE)

  if (length(unique(r$base_type)) == 1) {
    r$base_type <- NULL
  } else {
    r <- r %>% dplyr::group_by(id, condition, replicate) %>%
      dplyr::mutate(base_type = "total", bc_A = sum(bc_A), bc_C = sum(bc_C), bc_G = sum(bc_G), bc_T = sum(bc_T)) %>%
      dplyr::ungroup() %>%
      rbind(r)
  }

  r
}

#' Read multiple related JACUSA2 results
#' 
#' TODO
#' 
#' @param files Vector of files
#' @param meta_conditions Vector of character vectors that correspond to files
#' @return TODO
#'
#' @export
read_results <- function(files, meta_conditions) {
  stopifnot(length(files) == length(meta_conditions))
  
  # read all files  
  l <- mapply(function(file, meta_condition) {
    result <- read_result(file)
    result$meta_condition <- meta_condition
    result$id
    result
  }, files, meta_conditions)

  # combine read files
  results <- dplyr::bind_rows(l)
  results$meta_condition <- as.factor(results$meta_condition)
  # use meta_condition to re-index
  results$id <- dplyr::group_indices(
    results, meta_condition, contig, start, end, strand
  )
  
  results
}
