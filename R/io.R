#' Read JACUSA2 result file
#'
#' \code{read_result()} Reads data that was generated by JACUSA2 and creates a JACUSA2 result object.
#'
#' @param file String that represents the filename of the JACUSA2 output.
#' @param showProgress Boolean indicates if progress should be monitored.
#' @param desc Vector of strings that represent names/descriptions for conditions, default are integers.
#' @param cores Integer defines how many cores to use.
#'
#' @importFrom magrittr %>%
#'
#' @export
read_result <- function(file, showProgress = TRUE, desc = c(), cores = 1) {
  # pre process file
  # parse comments ^(#|##) to determine result/method type and number of conditions
  con <- file(file, "r")
  conditions <- 0
  skip_lines <- 0
  header_names <- NULL
  # possible result/method types: unknown, call-pileup, rt-arrest, lrt-arrest
  # type <- .UNKNOWN_METHOD_TYPE
  while (TRUE) {
    line = readLines(con, n = 1)
    # quit reading: nothing to read or first no header line 
    if (length(line) == 0 || length(grep("^#", line)) == 0) {
      break
    }
    # count header lines to ignore
    skip_lines <- skip_lines + 1

    if (length(grep("^#contig", line)) > 0) {
      # try to guess result/method by header line
      type <- .guess_file_type(line)
      # type will be vali or .guess_file_type throw error

      # parse and store header
      # fix header: #contig -> contig
      header_names <- sub("^#", "", line);
      header_names <- unlist(strsplit(header_names, "\t"))
      
      # guess number of conditions  
      conditions <- .guess_conditions(type, header_names)
    }
  }
  # finished pre-processing
  close(con)
  
  # check that a header could be parsed
  if (is.null(header_names)) {
    stop("No header line for file: ", file)
  }

  # check that conditions could be guessed
  if (conditions < 1) {
    stop("Conditions could not be guessed for file: ", file)
  }
  # and match any given description
  if (length(desc) & conditions != length(desc)) {
    stop("Length of description", length(desc), " and conditions(", conditions, ") don't match.")
  } else {
    desc <- paste0("cond", 1:conditions)
  }

  # read data
  data <- data.table::fread(file, 
                            skip = skip_lines, 
                            sep = "\t",
                            header = FALSE, 
                            showProgress = showProgress)  
  colnames(data) <- header_names

  # create result depending on determined method type 
  result <- .create_result(type, desc, data, cores)
  
  result
}


# create contig:start|start-end:strand
.coord <- function(data) {
  paste0(
    data$contig,
    ":", ifelse(data$end - data$start == 1, data$start, paste0(data$start, "-", data$end)),
    ":", data$strand
  )
}

.id <- function(data) {
  read_sub <- stringr::str_match(data$info, "(read_sub)=([^;]+)")[, 3]
  coord <- .coord(data)
  paste0(coord, ":", read_sub)
}


# Create result for type and conditions from data 
.create_result <- function(type, condition_desc, data, cores) {
  data$id <- .id(data)
  columns <- NULL
  if(type == .CALL_PILEUP_METHOD_TYPE) {
    columns <- c(.CALL_PILEUP_COLUMN)
  } else if (type == .RT_ARREST_METHOD_TYPE) {
    columns <- c(.RT_ARREST_COLUMN, .RT_THROUGH_COLUMN)
  } else if (type == .LRT_ARREST_METHOD_TYPE) {
    columns <- c(.RT_ARREST_COLUMN, .RT_THROUGH_COLUMN)
  } else {
    stop("Unknown type: ", type)
  }
  result <- .process_bases(data, columns, condition_desc, cores)
  if (type %in% c(.RT_ARREST_METHOD_TYPE, .LRT_ARREST_METHOD_TYPE)) {
    result[["bases"]] <- lapply(paste0("cond", 1:length(condition_desc)), function(x) {
      return(result[[.RT_ARREST_COLUMN]][[x]] + result[[.RT_THROUGH_COLUMN]][[x]])
    }) 
  }

  conditions <- length(condition_desc)
  
  condition_bases <- parallel::mclapply(result[["bases"]], function(x) {
    return(Reduce('+', x))
  }, mc.cores = min(conditions, cores), mc.preschedule = FALSE)
  total_bases <- Reduce('+', condition_bases)

  # add coverage  
  condition_cov <- parallel::mclapply(condition_bases, function(x) {
    return(rowSums(x))
  }, mc.cores = min(conditions, cores), mc.preschedule = FALSE)
  result[["cov"]] <- tidyr::as_tibble(condition_cov)
  result[["cov"]][["total"]] <- Reduce('+', condition_cov)

  # add base call
  bases <- parallel::mcmapply(function(base_counts, base) {
    return(ifelse(base_counts > 0, base, ""))
    }, total_bases, .BASES, mc.cores = min(length(.BASES), cores), mc.preschedule = FALSE
  )
  result <- dplyr::bind_cols(result, tidyr::as_tibble(bases) %>% tidyr::unite(!!!.BASES, sep = "", col = "bc"))
  # add allele count
  result$allele_count <- nchar(result$bc)

  # unpack info field
  info <- tidyr::separate_rows(result[, c("id", "info")], info, sep = ";")
  x <- strsplit(info$info, "=") %>% do.call(rbind, .) %>% as.data.frame() %>% tidyr::as_tibble()
  colnames(x) <- c("key", "value")
  info <- info[, "id"]
  info <- dplyr::bind_cols(info, x) %>% tidyr::pivot_wider(names_from = key, values_from=value)
  
  result <- dplyr::inner_join(result, info, by = "id")

  # parse indels ondemand
  if (any(c("insertion_score", "deletion_score") %in% names(result))) {
    result <- .process_indels(result, condition_desc, cores)
  }

  result
}


# helper function to extract deletion info(s)
.process_indels <- function(result, condition_desc, cores) {
  conditions <- length(condition_desc)
  types <- c("ins", "del")
  matches <- .matches(result, types, condition_desc) %>% na.omit()

  # fill EMPTY cells with 0,0
  cols <- unique(matches$"col")
  result[cols][is.na(result[cols])] <- paste0(rep(0, length(types)), collapse = ",")

  counts <- parallel::mclapply(result[cols], function(x) {
    x <- lapply(strsplit(x, ","), as.numeric) %>% 
      do.call(rbind, .) %>% 
      as.data.frame() %>%
      tidyr::as_tibble()
    colnames(x) <- c("reads", "coverage")
    return(x)
  }, mc.cores = cores, mc.preschedule = FALSE)
  names(counts) <- matches$col
  
  # remove expanded cols and convert
  result <- dplyr::select(result, !cols) %>% tidyr::as_tibble()

  for (type in types) {
    condition_dfs <- parallel::mclapply(1:conditions, function(condition) {
      cond_matches <- matches[matches$condition == condition & matches$type == type, ]
      # condition specific base call counts
      cond_counts <- counts[cond_matches$col]
      # prevent names to be integer
      names(cond_counts) <- paste0("rep", cond_matches$replicate)
      return(tidyr::as_tibble(cond_counts))
    }, mc.cores = min(conditions, cores), mc.preschedule = FALSE)
    names(condition_dfs) <- unique(matches$desc)
    result[[type]] <- tidyr::as_tibble(condition_dfs)
  }

  meta_cols <- c("deletion_score", "delete_pvalue", "insertion_score", "insertion_pvalue")
  for (col in c("deletion_score", "delete_pvalue", "insertion_score", "insertion_pvalue")) {
    if (col %in% names(df)) {
      df[[col]] <- as.numeric(df[[col]])
    }
  }

  result
}

.matches <- function(df, types, condition_desc) {
  conditions <- length(condition_desc)
  # regex parts:
  types_regex = paste0("^(", paste0(types, collapse = "|"), ")")
  condition_regex = paste0("([:digit:]{", nchar(conditions), "})")
  replicate_regex = "([:digit:]+)"
  # get relevant cols and disect to m(atch):
  # match, base_type, condition, replicate
  cols <- stringr::str_subset(names(df), types_regex)
  m <- stringr::str_match(
    cols,
    paste0(types_regex, condition_regex, replicate_regex)
  )
  colnames(m) <- c("col", "type", "condition", "replicate")
  matches <- as.data.frame(m, stringsAsFactors = FALSE)
  # add description
  matches["desc"] <- condition_desc[match(matches$condition, 1:length(condition_desc))]

  matches
}

# helper functions to create data container to hold data
.process_bases <- function(df, base_types, condition_desc, cores) {
  conditions <- length(condition_desc)
  matches = .matches(df, base_types, condition_desc)

  # fill EMPTY cells with 0,0,0,0
  cols <- unique(matches$"col")
  df[cols][df[cols] == .EMPTY] <- paste0(rep(0, length(JACUSA2helper:::.BASES)), collapse = ",")
  
  # expand base call columns from "," encoded strings
  # convert string: "0,10,2,0" to new columns: bc_A = 0, bc_C = 10, bc_G = 2, bc_T = 0
  bases <- parallel::mclapply(df[cols], function(x) {
    x <- lapply(strsplit(x, ","), as.numeric) %>% 
      do.call(rbind, .) %>% 
      as.data.frame() %>%
      tidyr::as_tibble()
    colnames(x) <- .BASES
    return(x)
  }, mc.cores = cores, mc.preschedule = FALSE)
  names(bases) <- matches$col

  # remove expanded cols and convert
  df <- dplyr::select(df, !cols) %>% tidyr::as_tibble()
  
  for (base_type in base_types) {
    condition_dfs <- parallel::mclapply(1:conditions, function(condition) {
      cond_matches <- matches[matches$condition == condition, ]
      # condition specific base call counts
      cond_bases <- bases[cond_matches$col]
      # prevent names to be integer
      names(cond_bases) <- paste0("rep", cond_matches$replicate)
      return(tidyr::as_tibble(cond_bases))
    }, mc.cores = min(conditions, cores), mc.preschedule = FALSE)
    names(condition_dfs) <- unique(matches$desc)
    df[[base_type]] <- tidyr::as_tibble(condition_dfs)
  }

  df
}

#' Read multiple related JACUSA2 results
#' 
#' TODO
#' 
#' @param files Vector of files
#' @param meta_conditions Vector of character vectors that correspond to files
#' @param cores Integer defines how many cores to use.
#'
#' @export
read_results <- function(files, meta_conditions, cores=1) {
  stopifnot(length(files) == length(meta_conditions))
  
  # read all files  
  l <- mcmapply(function(file, meta_condition) {
    result <- read_result(file)
    result$meta_condition <- meta_condition
    result$id
    result
  }, files, meta_conditions, mc.cores = cores)

  # combine read files
  results <- dplyr::bind_rows(l)
  results$meta_condition <- as.factor(results$meta_condition)

  results
}
