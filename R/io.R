#' Read JACUSA2 result file
#'
#' \code{read_result()} Reads data that was generated by JACUSA2 and creates a JACUSA2 object.
#'
#' @param file String that represents the filename of the JACUSA2 output.
#' @param showProgress Boolean indicates if progress should be monitored.
#'
#' @export
read_result <- function(file, showProgress = TRUE) {
  # pre process file
  # parse comments ^(#|##) to determine result/method type and number of conditions
  con <- file(file, "r")
  conditions <- 0
  skip_lines <- 0
  header_names <- NULL
  # possible result/method types: unknown, call-pileup, rt-arrest, lrt-arrest
  # type <- .UNKNOWN_METHOD_TYPE
  while (TRUE) {
    line = readLines(con, n = 1)
    # quit reading: nothing to read or first no header line 
    if (length(line) == 0 || length(grep("^#", line)) == 0) {
      break
    }
    # count header lines to ignore
    skip_lines <- skip_lines + 1

    if (length(grep("^#contig", line)) > 0) {
      # try to guess result/method by header line
      type <- .guess_file_type(line)
      # type will be vali or .guess_file_type throw error

      # parse and store header
      # fix header: #contig -> contig
      header_names <- sub("^#", "", line);
      header_names <- unlist(strsplit(header_names, "\t"))
      
      # guess number of conditions  
      conditions <- .guess_conditions(type, header_names)
    }
  }
  # finished pre-processing
  close(con)
  
  # check that a header could be parsed
  if (is.null(header_names)) {
    stop("No header line for file: ", file)
  }

  # check that conditions could be guessed
  if (conditions < 1) {
    stop("Conditions could not be guessed for file: ", file)
  }
  
  # read data
  data <- data.table::fread(file, 
                            skip = skip_lines, 
                            sep = "\t",
                            header = FALSE, 
                            showProgress = showProgress)  
  colnames(data) <- header_names

  # create combined position id from genomic coordinates
  data$id <- dplyr::group_indices(
    data, contig, start, end, strand
  )

  # create container depending on determined result/method type 
  container <- .create_container(type, conditions, data)
  
  container
}

# Create container for type and conditions from data 
.create_container <- function(type, conditions, data) {
  info <- data %>% dplyr::select(id, info)
  data$info <- NULL
  container <- NULL
  if(type == .CALL_PILEUP_METHOD_TYPE) {
    container <- .create_call_pileup(conditions, data)
  } else if (type == .RT_ARREST_METHOD_TYPE) {
    container <- .create_rt_arrest(conditions, data)
  } else if (type == .LRT_ARREST_METHOD_TYPE) {
    container <- .create_lrt_arrest(conditions, data)
  } else {
    stop("Unknown type: ", type)
  }
  container$type <- type

  # add base call
  bc <- apply(container[, paste0("bc_", .BASES)], 1, function(x) { 
    paste0(.BASES[x > 0], collapse = "")
  })
  # add allele count
  container$allele_count <- nchar(bc)
  container$bc <- bc

  # only parse deletions, if there are any
  if (any(grep("^deletion", info$info))) {
    container <- merge(
      container, 
      .process_deletion(conditions, info), 
      by = c("id", "condition", "replicate"),
      all.x = TRUE
    )
  }

  # make factors
  container$condition <- as.factor(container$condition)
  container$replicate <- as.factor(container$replicate)
  
  container
}

# helper function to extract deletion info(s)
.process_deletion <- function(conditions, info) {
  df <- info %>% 
    tidyr::separate_rows(info, .INFO_COLUMN, sep = ";") %>% 
    tidyr::separate(
      col = !! .INFO_COLUMN, 
      into = c("key", "value"), 
      sep = "=", fill = "right") %>% 
    dplyr::filter(key != .EMPTY) %>%
    tidyr::spread(key, value) %>% 
    tidyr::gather(
      key = "deletion_sample", 
      value = "deletion_counts", 
      dplyr::matches("^deletions")) %>%
    tidyr::extract(
      deletion_sample, 
      c("condition", "replicate"), 
      regex = paste0("^deletions([0-9]{", nchar(conditions), "})([0-9]+)"), 
      remove = TRUE, convert = TRUE) %>%
    tidyr::separate(deletion_counts, paste0("deletion_", c("reads", "coverage")), 
                         sep = ",", remove = TRUE, convert = TRUE)

  df$deletion_pvalue <- as.numeric(df$deletion_pvalue)
  df$deletion_score <- as.numeric(df$deletion_score)

  df
}

.create_bases <- function(conditions, dt, default_bases = "all") {
  # convert wide to long
  r <- tidyr::gather(dt, sample, bases, dplyr::contains(.CALL_PILEUP_COLUMN))
  i <- startsWith(r$sample, .CALL_PILEUP_COLUMN)
  if (length(i) > 0) {
    r$sample[i] <- paste0(default_bases, "_", r$sample[i])
  }

  # extract condition and replicate
  r <- tidyr::extract(r, sample, c("base_type", "condition", "replicate"), 
                      regex = paste0("^(.+)_", 
                                     .CALL_PILEUP_COLUMN, 
                                     "([0-9]{", 
                                     nchar(conditions), 
                                     "})([0-9]+)"), 
                      remove = TRUE, convert = TRUE)
  # extract base call columns from "," encoded strings
  # convert string: "0,10,2,0" to new columns: bc_A = 0, bc_C = 10, bc_G = 2, bc_T = 0
  r <- tidyr::separate(r, bases, paste0("bc_", c("A", "C", "G", "T")), 
                       sep = ",", remove = TRUE, convert = TRUE)

  if (length(unique(r$base_type)) == 1) {
    r$base_type <- NULL
  }
  
  r
}

# helper functions to create data container to hold data
.create_call_pileup <- function(dt, conditions) {
  r <- .create_bases(dt, conditions)

  r
}

.create_rt_arrest <- function(dt, conditions) {
  r <- .create_bases(dt, conditions)
  # TODO aggregate
  
  r
}

.create_lrt_arrest <- function(dt, conditions) {
  r <- .create_bases(dt, conditions)
  # TODO aggregate
  
  r
}

#' Read multiple related JACUSA2 results
#' 
#' TODO
#'
#' @param Vector of files
#' @param Vector of character vectors that correspond to files
#' @return TODO
#'
#' @export
read_results <- function(files, meta_conditions) {
  stopifnot(length(files) == length(meta_conditions))
  
  # read all files  
  l <- mapply(function(file, meta_condition) {
    j2 <- read_result(file)
    j2$meta_condition <- meta_condition
    j2$id
    j2
  }, files, meta_conditions)

  # combine read files
  js2 <- dplyr::bind_rows(l)
  js2$meta_condition <- as.factor(js2$meta_condition)
  # use meta_condition to re-index
  js2$id <- dplyr::group_indices(
    js2, meta_condition, contig, start, end, strand
  )
  
  js2
}
