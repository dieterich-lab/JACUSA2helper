---
title: "Analysis of Nanopore HEK293 with JACUSA2helper"
author: "Christoph Dieterich, Michael Piechotta"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: JACUSA2helper-nanopore.bib
link-citations: yes
vignette: >
  %\VignetteIndexEntry{Analysis of Nanopore HEK293 with JACUSA2helper}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
options(tibble.print_min = 4L, tibble.print_max = 4L)
set.seed(777)
```

In the following, the workflow for use case 3 from @Piechotta2021 is presented.
Data for [use cases 1-3](https://zenodo.org/record/5930729#.YfmTDFvMIUG) can be downloaded to repeat the analysis.

The following packages need to be loaded:
```{r,warning=FALSE,message=FALSE}
library(JACUSA2helper)
library(GenomicRanges)
library(BSgenome)
library(GenomeInfoDb)
library(plyranges)
library(magrittr)
library(dplyr)
library(ggplot2)
library(pROC)
library(VennDiagram)
library(NMF)
```

# Non-negative Matrix Factorization

Here, we briefly introduce Non-negative Matrix Factorization (NMF). This section uses the notation from [NMF vignette](https://cran.r-project.org/web/packages/NMF/vignettes/NMF-vignette.pdf).

Non-negative Matrix Factorization tries to find an approximation of:
$$X \approx W H$$,
where:

* $X$ is a non-negative $n \times p$ matrix,
* $W$ is a non-negative $n \times r$ matrix (basis matrix), and
* $H$ is a non-negative $r \times p$ matrix (coefficient matrix).

$r$ is called the factorization rank.

Check [NMF vignette](https://cran.r-project.org/web/packages/NMF/vignettes/NMF-vignette.pdf) for details on optimization and algorithms.

In the following, we will explain how to convert JACUSA2 output to an appropriate matrix $X$ and perform NMF.

# General workflow

Use `read_result` to read JACUSA2 output and filter the data set.

To repeat the Nanopore analysis from @Piechotta2021, download the following data:

* [WT vs. KO](https://zenodo.org/record/5940218/files/WT_vs_KO_call2_result.out.gz?download=1) and
* [WT100 vs. WT0](https://zenodo.org/record/5940218/files/WT100_vs_WT0_call2_result.out.gz?download=1).

Depending on your bandwidth the Download might take some time.
Download the data, start R and change into the directory where you have saved the files from zenodo.
Make sure, you have approx. 20GB of main memory available.

## Pre-processing

We start to organize the data:

```{r}
# files to read
files <- c(
  "WT_vs_KO_2samp_RC22_call2_result.out.gz",
  "WT100_vs_WT0_RC22_call2_result.out.gz"
)

# descriptions corresponding to files 
meta_conds = c(
  #"Exp1",
  #"Exp2"
  "WT_vs_KO",
  "WT100_vs_WT0"
)
```

```{r, include = FALSE}
files <- c(
  "/home/michael/TODO/JACUSA2helper/WT_vs_KO_2samp_RC22_call2_result.out.gz",
  "/home/michael/TODO/JACUSA2helper/WT100_vs_WT0_RC22_call2_result.out.gz"
)
setwd("/home/michael/TODO/JACUSA2helper/")
```

`meta_conds` is used as a concise description of each file to distinguish the JACUSA2 outputs.

The pre-processing workflow for one file can be summarized into the following steps:

Read
: Read JACUSA2 output.

Filter
: Employ coverage and other filters to remove not interesting sites.

Add meta condition
: Add concise description of each file.

Reduce
: Select relevant data column.

We explain the pre-processing workflow for one file and generalize to arbitrary number of files (here two).

<!-- TODO mention `read_results` 
### `read_results`

An other option to read the data set is via `read_results` - see `vignette(Introduction to meta conditions with JACUSA2helper)`.
Does not apply here because the data has different number of replicates.
This approach will consume much more main memory. We recommend to read big data sets serially with `read_result` and combine them afterwards.
-->

### Read 

The underlying function of `read_result` is `data.table::fread` - check the respective help page for details on additional options.
Depending on your machine increase `nThreads` to use more threads to parse a file.

The "info" field contains meta information for sites, such as detailed INDEL statistics.
To save memory, we manually unpack the "info" field and select the following keys:

* `insertion_score` and 
* `deletion_score`.

We will use these score values during model training.

```{r}
i <- 1 # WT_vs_KO
print(files[i])
print(meta_conds[i])

wt_vs_ko_res <- read_result(files[i], nThread = 2, unpack = c("insertion_score", "deletion_score"))
```

### Filter

The JACUSA2 output files from Zenodo have been already filtered to retain sites with coverage $> 4$ in all BAM files.

We use the following filter:

* retain sites on chromosome 1-22, MT, and X.

```{r}
print(paste0("Sites BEFORE filtering: ", length(wt_vs_ko_res)))

# reduce set of known sequences
seqlevels(wt_vs_ko_res, pruning.mode = "coarse") <- c(1:22, "MT", "X")

wt_vs_ko_filtered <- wt_vs_ko_res %>% filter(
    seqnames %in% c(as.character(1:22), "MT", "X")
)

print(paste0("Sites AFTER filtering: ", length(wt_vs_ko_filtered)))
```

### Add meta condition

We add a concise description of files to each result object.

```{r}
mcols(wt_vs_ko_filtered)$meta_cond <- factor(meta_conds[1], meta_conds)

table(wt_vs_ko_filtered$meta_cond)
```

`WT100_vs_WT0` is zero because we haven't added the respective file yet.

#### Add reference sequence information

Sequence lengths are necessary to check if coordinates are valid. 
Initially, a JACUSA2 result object has no information about the underlying reference sequence.

```{r}
seqlengths(wt_vs_ko_res)
```

We can either specify the genome (see `?GenomeInfoDb::seqinfo`) or 
add reference sequence information with `seqlengths()`:
```{r}
# load the package that corresponds to your genome
library("BSgenome.Hsapiens.NCBI.GRCh38")

seqlengths(wt_vs_ko_res) <- seqlengths(BSgenome.Hsapiens.NCBI.GRCh38)[names(seqlengths(wt_vs_ko_res))]
seqlengths(wt_vs_ko_res)
```

### Create matrix $X$

We continue to reduce the data set by selecting only relevant columns and renaming the "score" column to "call2_score" for consistency: 
Given a JACUSA2 result object, the function `creata_data()` will create a data matrix, that will be used in NMF. 
In brief, relevant score columns are rearranged and a region or context around each Adenin site is created.

```{r}
data_matrix = create_data(wt_vs_ko_filtered)
data_matrix[is.na(data_matrix)] <- 0
data_matrix[data_matrix < 0] <- 0

head(data_matrix)
```

This operation concludes the pre-processing workflow for one file.

```{r, include=FALSE}
rm(list = c("wt_vs_ko_res", "wt_vs_ko_filtered"))
```

### Generalize

So far, we have shown a detailed description of pre-processing one file. 
In the following, we provide code for arbitrary number of results/experiments/meta conditions:

```{r}
# pre-processing workflow for arbitrary number of files and meta conditions
results <- mapply(function(file, meta_cond) {
    result <- read_result(file, nThread = 3, unpack = c("insertion_score", "deletion_score")) %>%
      filter(seqnames %in% c(as.character(1:22), "MT", "X"))

    seqlevels(result, pruning.mode = "coarse") <- c(1:22, "MT", "X")
    result <- result[, c("score", "insertion_score", "deletion_score", "filter", "ref")]

    # add file specific condition
    mcols(result)$meta_cond <- factor(meta_cond, meta_conds)

    return(result)
  }, files, meta_conds, SIMPLIFY = FALSE, USE.NAMES = FALSE
)
```

We need to convert `results` to a GRanges object and we add sequence information.

```{r}
# convert and concatenate GenomicRanges
results <- unlist(GRangesList(results))

# add reference sequence information
seqlengths(results) <- seqlengths(BSgenome.Hsapiens.NCBI.GRCh38)[names(seqlengths(results))]

# retained sites per file / meta condition
table(results$meta_cond)
```

`results` now consists of filtered JACUSA2 calls for sites from all `files` and `meta_conds`.

The overlap of called sites from each experiment can be investigated with the following:

```{r}
# add unique ID for a site: contig:start-end:strand
results$id <- as.character(results)

# venn diagram of sites that are shared between files
meta_cond_plt <- venn.diagram(
  tapply(results$id, results$meta_cond, c),
  filename = NULL,
  lwd = 1,
  cex = 0.5,
  fontfamily = "sans",
  cat.cex = 0.9,
  cat.default.pos = "outer",
  cat.fontfamily = "sans",
)
grid.newpage()
grid.draw(meta_cond_plt)
```

## Create data matrix

We use `create_data()` to create the data matrix that will be used to learn the model. 
We add a context of 2nt around each site creating a region (-NN**A**NN-) where the putative modification site is positioned in the middle (= position 3) of the motif. Internally, `create_data()` removes sites that are within homopolymers (JACUSA2 filter flag: "Y").
Each column name of the data matrix has the following format: `{meta_cond}_{score}_{position}`, where:

`meta_cond`
: 
is meta condition information ($meta_cond \in {WT_vs_KO, WT100_vs_WT}$)
`score`
: 
type of score $score \in {call2, insertion, or deletion}$
`position`
: 
position information within the region ($position \in {1, ..., 5}$).

```{r}
data_matrix <- create_data(results)

# set sensible defaults
data_matrix[is.na(data_matrix)] <- 0
data_matrix[data_matrix < 0] <- 0
```

Next, we filter the data matrix and require that each region has to be covered in both experiments.

```{r}
# contains score sum for each meta condition
score_sums <- rowsum(
  t(data_matrix),
  strcapture(
    paste0("^(", paste0(meta_conds, collapse = "|"), ")"), 
    colnames(data_matrix), 
    data.frame(meta_cond = character())
  )$meta_cond
) %>% t()

# score sum must be > 0 in all experiments
keep <- rowSums(score_sums > 0) == length(meta_conds)
data_matrix <- data_matrix[keep, ]
```

We will continue adding meta information to the data matrix to study the properties of sites.

### Add sequence

In order to add information if a site is contained in a DRACH motif, we need to retrieve the sequence context for a site.

If you have a custom FASTA sequence, use `Rsamtools::FaFile` to load the FASTA file.
Otherwise, load a genome from via [BSgenome](https://bioconductor.org/packages/release/bioc/html/BSgenome.html).

```{r}
# retrieve sequence and convert to character vector
data_matrix$motif <- getSeq(BSgenome.Hsapiens.NCBI.GRCh38, GRanges(rownames(data_matrix))) %>% 
  as.character() %>% 
  unname()

# number of top 10 motifs
sort(table(data_matrix$motif), decreasing = TRUE)[1:10]
```

Next, we add an indicator variable if the DRACH motif ([AGT][AG]AC[ACT]) is present:

```{r}
data_matrix$DRACH <- "no"
data_matrix$DRACH[grep("[AGT][AG]AC[ACT]", data_matrix$motif)] <- "yes"

tbl <- table(data_matrix$DRACH)
names(tbl) <- names(tbl) %>% 
  paste0(
    " (", 
    paste0(
      scales::label_comma()(as.vector(tbl)), 
      "; ", 
      scales::percent_format()(as.vector(tbl / sum(tbl)))
    ), 
    ")"
  )

# plot distribution of DRACH motifs
pie(tbl, mai = "DRACH motif present")
```

Use `saveRDS(data_matrix, file = "data_matrix.rds")` to store the current state.
Use `data_matrix <- readRDS("data_matrix.rds")` to restore previous state.

# Use NMF on Nanopore data

## Overlap with miCLIP data

Next, we use existing miCLIP data to train the model.

The data can be investigated with: `data(m6a_miclip)`. It consists of 3 experiments:

* @koh_atlas_2019,
* @boulias_identification_2019, and
* @kortel_deep_2021.

The column "experiments" indicates the source of a site.

Plot venn diagram of shared CLIP sites:

```{r}
miclip_plt <- m6a_miclip %>%
  mutate(site = as.character(.)) %>%
  as.data.frame() %>%
  tidyr::separate_rows(experiments) %>%
  with(tapply(site, experiments, list)) %>%
  venn.diagram(
    filename = NULL,
    lwd = 1,
    cex = 0.5,
    fontfamily = "sans",
    cat.cex = 0.9,
    cat.default.pos = "outer",
    cat.fontfamily = "sans",
  )
grid.newpage()
grid.draw(miclip_plt)
```

We add miCLIP information to `data_matrix`:

```{r}
data(m6a_miclip)

# Add region around site to miCLIP data
m6a_miclip_region <- extend(m6a_miclip, left = 2, right = 2)
m6a_miclip_region$experiments <- m6a_miclip$experiments

miclip_covered <- subsetByOverlaps(
  m6a_miclip_region,
  GRanges(rownames(data_matrix)),
  type = "equal"
)
data_matrix$experiments <- "-"
data_matrix[as.character(miclip_covered), "experiments"] <- miclip_covered$experiments

table(data_matrix$experiments)
```

Next, we create the data matrix (corresponds to $X$ in $N \approx W H$) of sites that are contained in all three data sets: Boulias, Koertel, and Koh. It will be used to learn the modification patterns:

```{r}
# retain sites that overlap with 3 miCLIP experiments

keep <- data_matrix$experiments == "Boulias,Koertel,Koh"
train_matrix <- data_matrix[keep, ]

table(train_matrix$DRACH)
```

## Compute factorizaion rank(s)

An important parameter in NMF is the factorization rank $r$ that defines the number of features to approximate $X$ - a similar parameter such as the number of clusters in the k-means algorithm. We will compute multiple factorizations with different values for $r$ and use surrogate measures to find an appropriate value.

Make sure that the data/train matrix ($X$) contains only numeric values before you start the factorization of $X$ to $W H$.
The functions that does the calculations in JACUSA2helper is `nmf_learn(x, mods)`, where `x` is the data/train matrix and mods is a GRanges object of known modifications.

Internally, JACUSA2helper uses the NMF package. 
Check [NMF vignette](https://cran.r-project.org/web/packages/NMF/vignettes/NMF-vignette.pdf) for details on parameters.
The default parameters in JACUSA2helper are set to `nmf_args = list(rank = 2:10, nrun = 10, seed = 123456, .opt = "vp4")`.
For example argument `.opt=pv3` instructs to use 3 cores - adjust the number according to your machine.

When using the default parameters, factorizations for rank $r \in {2, ..., 10}$ will be computed:

```{r,warning=FALSE,message=FALSE}
nmf_results <- learn_nmf(
  train_matrix %>% select(-c(motif, DRACH, experiments))
)
```

The result `nmf_results` is a list that consists of the following data:

`estim_r`
: Factorizations for `x`
`nmf_matrix`
: Factorization of `x` with `r` that maximizes `estim_r$measures$silhouette.consensus` and `estim_r$measures$cophenetic`
`chosen_rank`
: Optimal rank
`chosen_pattern`
: The pattern that has the highest score

In the next steps, we will evaluate the learned model by comparing it against a null model.

### Visualize estimation of the ranks

We permutate the initial data and learn a randomized model:

```{r,warning=FALSE,message=FALSE}
nmf_random <- learn_nmf(
  train_matrix %>% 
    select(-c(motif, DRACH, experiments)) %>%
    randomize()
)
```

In the following, we will compare the results for different factorizations on the original and randomized data:

```{r,warning=FALSE,message=FALSE}
# compare factorization on original and randomized data
plot(nmf_results$estim_r, nmf_random$estim_r)
```
The optimal value of $r$ is the minimum rank for which rank `Silhouette` and `Cophenetic` is maximized.

## Visualize NMF

### Basis components

Plot properties of $W$.

```{r}
basismap(nmf_results$nmf_matrix)
```

### Mixture components

Plot properties of $H$.

```{r}
coefmap(nmf_results$nmf_matrix)
```

## Visualize patterns

```{r}
w <- basis(nmf_results$nmf_matrix)
# Table of number of best hits for each pattern"
pattern_instances <- apply(w, 1, function(x) {
    which(x == max(x))
  }
)
pattern_instance_tbl <- table(pattern_instances)

barplot(
  height = pattern_instance_tbl,
  names = 1:ncol(w),
  main = "NMF Patterns Scoring", 
  xlab = "Patterns", 
  ylab = "Membership Score (basis matrix)",
  ylim = range(pretty(c(0, pattern_instance_tbl)))
)
```

From this plot, we see that the highest score can observed for pattern:

```{r}
nmf_results$chosen_pattern
```

Next, we visualize the sequence logos that correspond to calculated patterns in NMF.

```{r,warning=FALSE,message=FALSE}
h <- coef(nmf_results$nmf_matrix)

sequences <- lapply(1:nrow(h), function(k) {
  region_index <- rownames(train_matrix) %in% names(which(pattern_instances == k))
  return(train_matrix[region_index, "motif"])
})
names(sequences) <- paste0("Pattern ", 1:nrow(h))
ggseqlogo::ggseqlogo(sequences)
```

Finally, we plot profiles for each pattern and experiment (meta condition):

```{r}
as.data.frame(h) %>% 
  mutate(pattern = 1:nrow(.)) %>% 
  tidyr::pivot_longer(
    -pattern, 
    names_to = c("Exp", "Score", "Pos"), 
    names_pattern = "(WT_vs_KO|WT100_vs_WT0)_(call2_score|deletion_score|insertion_score)_([1-5]+)"
  ) %>% 
  mutate(score = gsub("_score$", "", Score)) %>% 
  ggplot(aes(x = Pos, y = value, fill = Score)) + 
    geom_bar(stat = "identity") + 
    xlab("Position in motif\n-NN A NN-") +
    ylab("") +
    facet_grid(Exp ~ pattern, labeller = label_both)
```

## Prediction

We evaluate the factorization on the previously introduced miCLIP data. We use all sites.
WARNING! Make sure that the order of columns is correct - use `create_data()`.

```{r}
score_matrix <- predict_mods(
  data_matrix %>% select(-c(motif, DRACH, experiments)), 
  nmf_results
)
```

`score_matrix` consists of columns scores for each pattern and the `score` for the chosen pattern (in this case: `NMF5` = `score`).
We add meta information from `data_matrix` to `score_matrix`.
```{r}
score_matrix <- cbind(score_matrix, data_matrix[, c("motif", "DRACH", "experiments")])

head(score_matrix)
```

Sort `score_matrix` by column `score` - the best predictions will appear in the upper part of matrix.

## Evaluation

```{r}
score_matrix$clip <- if_else(score_matrix$experiments != "-", "CLIP", "No Clip")
score_matrix$type <- "-"

train <- score_matrix$experiments == "Boulias,Koertel,Koh"
score_matrix$type[train] <- "train"
score_matrix$type[!train] <- "evaluate"

table(score_matrix$clip, score_matrix$type)
```

```{r}
test_matrix <- score_matrix[score_matrix$type == "evaluate", ]
r <- roc(
  ifelse(test_matrix[, "clip"] == "CLIP", 1, 0), 
  test_matrix[, "score"]
)
```

```{r}
coordinates <- coords(r, x = "all", input = "threshold", ret = c("threshold","ppv","tpr","tp", "tn","fp","fn"))
coordinates$sum <- log2(coordinates$tp + coordinates$fp)
coordinates$ppv <- coordinates$ppv * 20
coordinates <- coordinates[which(coordinates$sum > log2(10)),]
```

```{r}
ggplot(coordinates, aes(x = threshold)) +  
  geom_line(aes(y = sum), size = 2, color = "#009E73") + 
  geom_line(aes(y = ppv), size = 2, color = "#D55E00") +
  scale_y_continuous(
    # Features of the first axis
    name = "Log2(#predicted modified)",
    # Add a second axis and specify its features
    sec.axis = sec_axis(~.*5, name = "PPV (miCLIP)")
  ) +  
  scale_x_continuous(name = "JACUSA2 NMF Score") + 
  theme_bw() +
  theme(
    axis.title.x = element_text(size = rel(2)),      
    axis.title.y = element_text(color = "#009E73", size = rel(2)),
    axis.title.y.right = element_text(color = "#D55E00", size = rel(0.9)), 
    axis.text = element_text(size = rel(1.5))
  )
```

# Prediction on 1 experiment

In the following we will show to predict modification sites on one experiment.
We will use WT vs KO from the previous example.

## Prepare data
```{r}
WT_vs_KO_data <- cbind(
  data_matrix[, grep("^WT_vs_KO", colnames(data_matrix))],
  data_matrix[, c("motif", "DRACH", "experiments")]
)
WT_vs_KO_data$clip <- if_else(WT_vs_KO_data$experiments != "-", "CLIP", "No Clip")
WT_vs_KO_data$type <- "-"

train <- WT_vs_KO_data$experiments == "Boulias,Koertel,Koh"
WT_vs_KO_data$type[train] <- "train"
WT_vs_KO_data$type[!train] <- "evaluate"
```

## Reduce h

We need to adjust the coefficient matrix. We combine the coefficient from NMF on WT vs KO and WT100 vs WT0 with
the mean function.

```{r}
t_h <- coef(nmf_results$nmf_matrix) %>%
  t() %>%
  as.data.frame()

t_h$score_types <- gsub(paste0("(", meta_conds, ")_", collapse = "|"), "", rownames(t_h))
t_h <- t_h %>% 
  group_by(score_types) %>%
  summarise_at(paste0("V", 1:(ncol(t_h) - 1)), mean) %>%
  select(-score_types) %>%
  as.matrix()
```


## Create scores

```{r}
WT_vs_KO_scores <- as.matrix(select(WT_vs_KO_data, -c(motif, DRACH, experiments, clip, type))) %*% t_h
WT_vs_KO_score <- WT_vs_KO_scores[, nmf_results$chosen_pattern]

WT_vs_KO_scores <- as.data.frame(WT_vs_KO_scores)
colnames(WT_vs_KO_scores) <- paste0("NMF", 1:ncol(WT_vs_KO_scores))
WT_vs_KO_scores[["score"]] <- WT_vs_KO_score

WT_vs_KO_scores <- cbind(WT_vs_KO_scores, WT_vs_KO_data[, c("clip", "type")])
```

```{r}
WT_vs_KO_test <- WT_vs_KO_scores[WT_vs_KO_scores$type == "evaluate", ]
WT_vs_KO_roc <- roc(
  ifelse(WT_vs_KO_test[, "clip"] == "CLIP", 1, 0), 
  WT_vs_KO_test[, "score"]
)
```

## Evaluate

```{r}
WT_vs_KO_coords <- coords(WT_vs_KO_roc, x = "all", input = "threshold", ret = c("threshold","ppv","tpr","tp", "tn","fp","fn"))
WT_vs_KO_coords$sum <- log2(WT_vs_KO_coords$tp + WT_vs_KO_coords$fp)
WT_vs_KO_coords$ppv <- WT_vs_KO_coords$ppv * 20
WT_vs_KO_coords <- WT_vs_KO_coords[which(WT_vs_KO_coords$sum > log2(10)),]
```

```{r}
ggplot(WT_vs_KO_coords, aes(x = threshold)) +  
  geom_line(aes(y = sum), size = 2, color = "#009E73") + 
  geom_line(aes(y = ppv), size = 2, color = "#D55E00") +
  scale_y_continuous(
    # Features of the first axis
    name = "Log2(#predicted modified)",
    # Add a second axis and specify its features
    sec.axis = sec_axis(~.*5, name = "PPV (miCLIP)")
  ) +  
  scale_x_continuous(name = "JACUSA2 NMF Score") + 
  theme_bw() +
  theme(
    axis.title.x = element_text(size = rel(2)),      
    axis.title.y = element_text(color = "#009E73", size = rel(2)),
    axis.title.y.right = element_text(color = "#D55E00", size = rel(0.9)), 
    axis.text = element_text(size = rel(1.5))
  )
```

# References
