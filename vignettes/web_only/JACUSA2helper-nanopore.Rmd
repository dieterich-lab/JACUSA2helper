---
title: "Analysis of Nanopore HEK293 with JACUSA2helper"
author: "Christoph Dieterich, Michael Piechotta"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: JACUSA2helper-nanopore.bib
link-citations: yes
vignette: >
  %\VignetteIndexEntry{Analysis of Nanopore HEK293 with JACUSA2helper}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
options(tibble.print_min = 4L, tibble.print_max = 4L)
library(JACUSA2helper)
library(GenomicRanges)
library(BSgenome)
library(plyranges)
library(magrittr)
library(dplyr)
library(ggplot2)
library(pROC)
library(VennDiagram)


miclip <- read.delim(
  "/storage/JACUSA2_TestField/Nanopore/miCLIP_union_flat_exclude_Y_chromosome.bed", 
  header = FALSE, as.is = TRUE, 
  col.names = c("contig", "start", "end", "overlap", "score", "strand")
)
miclip$start <- miclip$start - 2
miclip$end <- miclip$end + 2
miclip$region <- paste0(miclip$contig, ":", miclip$start + 1, "-", miclip$end, ":", miclip$strand)

set.seed(777)
```

In the following, the workflow for use case 3 from @Piechotta20221 is presented.
Data for [use cases 1-3](https://zenodo.org/record/5930729#.YfmTDFvMIUG) can be downloaded to repeat the analysis.

# Non-negative Matrix Factorization

Here, we briefly introduce Non-negative Matrix Factorization (NMF). This section uses the notation from [NMF vignette](https://cran.r-project.org/web/packages/NMF/vignettes/NMF-vignette.pdf).

Non-negative Matrix Factorization tries to find an approximation of:
$$X \approx W H$$,
where
* $X$ is a non-negative $n \times p$ matrix,
* $W$ is a non-negative $n \times r$ matrix (basis matrix), and
* $H$ is a non-negative $r \times p$ matrix (coefficient matrix).

$r$ is called the factorization rank.

Check [NMF vignette](https://cran.r-project.org/web/packages/NMF/vignettes/NMF-vignette.pdf) for details on optimization and algorithms.

In the following, we will explain how to convert JACUSA2 output to an appropriate matrix $X$ and perform NMF.

# General workflow

Use `read_result` to read JACUSA2 output and filter the data set.

To repeat the Nanopore analysis from @Piechotta2021, download the following data:
* [WT100 vs. WT0](https://zenodo.org/record/5940218/files/WT100_vs_WT0_call2_result.out.gz?download=1).
* [WT vs. KO](https://zenodo.org/record/5940218/files/WT_vs_KO_call2_result.out.gz?download=1) and

Depending on your bandwidth the Download might take some time.
Make sure, you have approx. 20GB of main memory available.

## Pre-processing

At the beginning we organize the data:
```{r}
# files to read
files <- c(
  "/storage/zenodo/use_case3/WT_vs_KO_call2_result.out.gz",
  "/storage/zenodo/use_case3/WT100_vs_WT0_call2_result.out.gz"
)

# descriptions corresponding to files 
meta_conds = c(
  "WT_vs_KO",
  "WT100_vs_WT0"
)
```

`meta_conds` is used as a concise description of each file to distinguish the JACUSA2 outputs.

The pre-processing workflow for one file can be summarized into the following steps:

Read
: Read JACUSA2 output.

Filter
: Employ coverage and other filters to remove not interesting sites.

Add meta condition
: Add concise description of each file.

Unpack and add info
: Unpack specific info data and add.

Reduce
: Select relevant data column.

We explain the pre-processing workflow for one file and generalize to arbitrary number of files (here two).

<!-- TODO mention `read_results` 
### `read_results`

An other option to read the data set is via `read_results` - see `vignette(Introduction to meta conditions with JACUSA2helper)`.
Does not apply here because the data has different number of replicates.
This approach will consume much more main memory. We recommend to read big data sets serially with `read_result` and combine them afterwards.
-->

### Read 
The underlying function of `read_result` is `data.table::fread` - check the respective help page for details on additional options.
Depending on your machine increase `nThreads` to use more threads to parse a file.

```{r}
i <- 1 # WT_vs_KO
print(files[i])
print(meta_conds[i])

wt_vs_ko_res <- read_result(files[i], nThread = 1)
```

### Filter
We use the following filters:
* retain sites with "A" in the reference,
* retain sites on chromosome 1-22, and X, and
* remove sites that are within homopolymers (JACUSA2 filter flag: "Y").

```{r}
print(paste0("Sites BEFORE filtering: ", length(wt_vs_ko_res)))

wt_vs_ko_filtered <- wt_vs_ko_res %>% filter(
    ref == "A",
    seqnames %in% c(as.character(1:22), "X"),
    ! grepl("Y", filter, fixed = TRUE)
)

print(paste0("Sites AFTER filtering: ", length(wt_vs_ko_filtered)))
```

### Add meta condition

We add a concise description of files to each result object.

```{r}
wt_vs_ko_filtered$meta_cond <- factor(meta_conds[1], meta_conds)

table(wt_vs_ko_filtered$meta_cond)
```

`WT100_vs_WT0` is zero because we haven't added the respective file yet.

### Add specific info

The "info" field contains meta information for sites, such as detailed INDEL statistics.
To save memory, we manually unpack the "info" field and select the following keys:
* "insertion_score" and 
* "deletion_score".
We will use these values during model training.

```{r}
unpacked_info <- unpack_info(
    wt_vs_ko_filtered$info, 
    cond_count = 2, 
    keys=c("insertion_score", "deletion_score")
  )

# append specific info
mcols(wt_vs_ko_filtered) <- cbind(mcols(wt_vs_ko_filtered), unpacked_info)
```

### Reduce

We continue to reduce the data set by selecting only relevant columns and renaming "score" column to "call2_score" for consistency: 

```{r}
print(
  paste0(
    "Dimensions BEFORE reduction: ", 
    paste0(dim(mcols(wt_vs_ko_filtered)), collapse = ", ")
  )
)

mcols(wt_vs_ko_filtered) <- mcols(wt_vs_ko_filtered)[c("meta_cond", "score", "insertion_score", "deletion_score")]
colnames(mcols(wt_vs_ko_filtered))[colnames(mcols(wt_vs_ko_filtered)) == "score"] <- "call2_score"

print(
  paste0(
    "Dimensions AFTER reduction: ", 
    paste0(dim(mcols(wt_vs_ko_filtered)), collapse = ", ")
  )
)
```
This operation concludes the pre-processing workflow for one file.

### Generalize

So far, we have shown a detailed description of pre-processing one file. 
In the following, we provide code for arbitrary number of results and meta conditions:

```{r}
# pre-processing workflow for arbitrary number of files and meta conditions
results <- mapply(function(file, meta_cond) {
    result <- read_result(file, nThread = 1) %>%
      filter(
        ref == "A",
        ! grepl("Y", filter, fixed = TRUE),
        seqnames %in% c(as.character(1:22), "X")
      )
    # add file specific condition
    result$meta_cond <- factor(meta_cond, meta_conds)

    # unpack specific info
    unpacked_info <- unpack_info(
      result$info, 
      cond_count = 2, 
      keys=c("insertion_score", "deletion_score")
    )
    # add specific info
    mcols(result) <- cbind(mcols(result), unpacked_info)
    
    # select relevant data 
    mcols(result) <- mcols(result)[c("meta_cond", "score", "insertion_score", "deletion_score")]
    colnames(mcols(result))[colnames(mcols(result)) == "score"] <- "call2_score"

    return(result)
  }, files, meta_conds, SIMPLIFY = FALSE, USE.NAMES = FALSE)

# convert and concatenate GenomicRanges
results <- unlist(GRangesList(results))

# filtered sites per file / meta condition
table(results$meta_cond)
```

`results` now consists of locations and scores for sites from all `files` and `meta_conds`.

```{r}
# add unique ID for a site: contig:start-end:strand
results$id <- JACUSA2helper::id(results)

# venndiagram of sites shared betwen files
meta_cond_plt <- venn.diagram(
  tapply(results$id, results$meta_cond, c),
  filename = NULL,
  lwd = 1,
  cex = 0.5,
  fontfamily = "sans",
  cat.cex = 0.9,
  cat.default.pos = "outer",
  cat.fontfamily = "sans",
)
grid.newpage()
grid.draw(meta_cond_plt)
```

## Calculating overlapping regions

We extend the coordinates of a site by 2nt in each direction:
```{r}
extended_sites <- extend(results, left=2, right=2)

unique_regions <- unique(extended_sites)
```

`unique_regions` consists now of 5nt wide coordinates around all sites with the site (-NN**A**NN-) positioned in the middle (= position 3).
We calculate the position of each site in overlapping `unique_regions`:

```{r}
# compute overlap
hits <- findOverlaps(results, unique_regions)
# corresponding overlap in ...
overlap_regions <- unique_regions[subjectHits(hits)]
# and ...
overlap_results <- results[queryHits(hits)]

# coordinates of overlapping region: contig:start-end:strand
# bin sites in unique_regions
overlap_results$region <- paste0(
  seqnames(overlap_regions), ":",
  start(overlap_regions), "-", end(overlap_regions), ":",
  strand(overlap_regions)
)

# add site position within extended region
overlap_results$position <- start(overlap_results) - start(overlap_regions) + 1

barplot(
  table(overlap_results$position),
  xlab = "position of site within a motif\n(original site position is 3)",
  ylab = "Number of sites with score(s)",
  names.arg = c("1\n-N", "2\nN", "3\nA", "4\nN", "5\nN-")
)
```

## Create data matrix

The pre-processing is almost done, the data frame should contain the following columns:

```{r}
mcols(overlap_results)
```

Use `tidyr::pivot_wider` to create a data matrix:

```{r}
data_matrix <- mcols(overlap_results) %>% 
  as.data.frame() %>%
  tidyr::pivot_wider(
    id_cols = region, 
    names_from = c(meta_cond, position), 
    values_from = c(call2_score, insertion_score, deletion_score), 
    names_glue = "{meta_cond}_{.value}_{position}",
    names_sort = TRUE,
    values_fill = 0.0
  )

# set sensible defaults
data_matrix[is.na(data_matrix)] <- 0
data_matrix[data_matrix < 0] <- 0

colnames(data_matrix)
```

The columns of the data matrix correspond to scores for each meta condition and corresponding position in the motif, e.g. "WT_vs_KO_call2_score_4":
WT_vs_KO
: Meta condition.
call2_score
: score that indicates if base composition between condition is different.
4
: Position within motif

We will continue adding meta information to the data matrix.

### Add sequence

In order to add information if a site is contained in a DRACH motif, we need to retrieve sequence information for
the overlapping `unique_regions` of a site.

If you have a custom FASTA sequence, use `Rsamtools::FaFile` to load the FASTA file.
Otherwise, load a genome from via [BSgenome](https://bioconductor.org/packages/release/bioc/html/BSgenome.html).

```{r}
library("BSgenome.Hsapiens.NCBI.GRCh38")

# retrieve sequence and convert to character vector
data_matrix$motif <- getSeq(BSgenome.Hsapiens.NCBI.GRCh38, GRanges(data_matrix$region)) %>% 
  as.character() %>% unname()

# number of top 10 motifs
sort(table(data_matrix$motif), decreasing = TRUE)[1:10]
```

Next, we add an indicator variable if the DRACH motif ([AGT][AG]AC[ACT]) is present:

```{r}
data_matrix$DRACH <- 0
data_matrix$DRACH[grep("[AGT][AG]AC[ACT]", data_matrix$motif)] <- 1

tbl <- table(data_matrix$DRACH)
names(tbl) <- recode(names(tbl), "0" = "no", "1" = "yes")  %>% 
  paste0(
    " (", 
    paste0(
      scales::label_comma()(as.vector(tbl)), 
      "; ", 
      scales::percent_format()(as.vector(tbl / sum(tbl)))
    ), 
    ")"
  )

# plot distribution of DRACH motifs
pie(tbl, main="DRACH motif present")
```

Use `saveRDS(data_matrix, file = "data_matrix")` to store the current state.
Use `data_matrix <- readRDS("data_matrix")` to restore previous state.

# Use NMF on Nanopore data

## Overlap with miCLIP data

Next, we need miCLIP data to extract m6A sites from the data matrix:
* Boulias,
* Koertel, and
* Koh.
We use sites that are present in all three data sets.

The column "region" corresponds to the extended sites around identified miCLIP sites.
Make sure that "region" is 1-indexed if you use your own annotation.

```{r}
head(miclip)
```

```{r}
# plot venn diagram of shared CLIP sites
miclip_plt <- tidyr::separate_rows(miclip[c("overlap", "region")], overlap) %>% 
  with(tapply(region, overlap, list)) %>%
  venn.diagram(
    filename = NULL,
    lwd = 1,
    cex = 0.5,
    fontfamily = "sans",
    cat.cex = 0.9,
    cat.default.pos = "outer",
    cat.fontfamily = "sans",
)
grid.newpage()
grid.draw(miclip_plt)
```

Intersect regions and create feature matrix (corresponds to $X$ in $N \approx W H$) of sites that are contained in all three data sets: Boulias, Koertel, and Koh.
NMF requires the matrix to consist only of numeric and non-negative values:

```{r}
# retain sites that overlap with miCLIP and remove non-numeric columns
feature_matrix <- data_matrix[data_matrix$region %in% miclip[miclip$overlap == "Boulias,Koertel,Koh", "region"], ] %>% 
  as.data.frame()
rownames(feature_matrix) <- feature_matrix$region

# remove non-numeric columns
feature_matrix <- select(feature_matrix, -region, -motif, -DRACH)

feature_matrix
```

## Compute factorizaion rank(s)

An important parameter in NMF is the factorization rank $r$ that defines the number of features to approximate $X$ - a similar parameter like the number of clusters in the k-means algorithm. We will compute multiple factorizations with different values for $r$ and use a surrogate measure to find an appropriate value.

Make sure that the feature matrix ($X$) contains only numeric values before you start the factorization of $X$ to $W H$.
Check [NMF vignette](https://cran.r-project.org/web/packages/NMF/vignettes/NMF-vignette.pdf) for details on parameters.
For example argument `.opt=pv3` insructs to use for 3 cores - adjust the number according to your machine.

Here, we will compute factorizations for $r \in {2, ..., 10}$:

```{r,warning=FALSE,message=FALSE}
library(NMF)
nmfSeed('nndsvd')

estim.r <- nmf(feature_matrix, rank = 2:10, nrun = 10, seed = 123456, .opt = 'vp3')
```

### Visualize estimation of the ranks

In the following, we will compare the results for different $r$ on our original and randomized data (use default NMF algorithm):

```{r,warning=FALSE,message=FALSE}
# randomize original data
V.random <- randomize(feature_matrix)

# calculate factorization on randomized data
estim.r.random <- nmf(V.random, rank = 2:10, nrun=10, seed = 123456, .opt='vp3')

# compare factorization on original and randomized data
plot(estim.r, estim.r.random)
```

### Choose factorization rank

```{r}
DeltaSil <- estim.r$measures$silhouette.consensus - estim.r.random$measures$silhouette.consensus
DeltaCoph <- estim.r$measures$cophenetic - estim.r.random$measures$cophenetic

# how can we select factorization rank ?
ChoseRank <- min(
  which(DeltaSil == max(DeltaSil)) + 1,
  which(DeltaCoph == max(DeltaCoph)) + 1
)
```

Plot distribution of surrogate scores to select an appropriate factorization range $r$.

```{r}
val_matrix <- matrix(0, nrow = length(DeltaCoph), ncol = 2)
val_matrix[, 1] <- DeltaSil 
val_matrix[, 2] <- DeltaCoph

barplot(
  t(val_matrix), 
  names.arg = 2:(length(DeltaCoph) + 1), 
  beside = TRUE, 
  col = c("#009E73", "#D55E00"), 
  legend.text = c("Silhouette", "Cophenetic"),
  ylim = range(
    pretty(c(0, DeltaSil))), 
  xlab = "Rank", 
  ylab = "Delta", 
  main = "Difference between original and randomized data",
  cex.names=2,
  cex.axis=2
)
abline(h = c(max(DeltaSil), max(DeltaCoph)), col = c("#009E73", "#D55E00"))
```

Compute factorization with chosen rank.

```{r,warning=FALSE,message=FALSE}
nmf_matrix <- nmf(feature_matrix, ChoseRank, nrun=10, seed=123456, .opt='vp3')
```

Use `saveRDS(nmf_matrix, file="nmf_matrix")` to store final result.

## Visualize NMF

### Basis components

Plot properties of $W$.

```{r}
basismap(nmf_matrix)
```
### Mixture components

Plot properties of $H$.

```{r}
coefmap(nmf_matrix)
```

## Visualize patterns

```{r}
w <- basis(nmf_matrix)
# Table of number of best hits for each pattern"
pattern_instances <- apply(w, 1, function(x) {
    which(x == max(x))
  }
)
pattern_instance_tbl <- table(pattern_instances)

barplot(
  height = pattern_instance_tbl,
  names = 1:ncol(w),
  main = "NMF Patterns Scoring", 
  xlab = "Patterns", 
  ylab = "Membership Score (basis matrix)",
  ylim = range(pretty(c(0, pattern_instance_tbl)))
)
```

Next, we visualize the sequence logos that correspond to calculated patterns in NMF.

```{r,warning=FALSE,message=FALSE}
h <- coef(nmf_matrix)

sequences <- lapply(1:nrow(h), function(k) {
  region_index <- data_matrix$region %in% names(which(pattern_instances == k))
  return(data_matrix[region_index, "motif"]$motif)
})
names(sequences) <- paste0("Pattern ", 1:nrow(h))
ggseqlogo::ggseqlogo(sequences)
```

Finally, we plot profiles for each pattern and experiment (meta condition):

```{r}
as.data.frame(h) %>% 
  mutate(pattern = 1:nrow(.)) %>% 
  tidyr::pivot_longer(
    -pattern, 
    names_to = c("Exp", "Score", "Pos"), 
    names_pattern = "(WT_vs_KO|WT100_vs_WT0)_(call2_score|deletion_score|insertion_score)_([1-5]+)") %>% 
  mutate(score = gsub("_score$", "", Score)) %>% 
  ggplot(aes(x = Pos, y = value, fill = Score)) + 
    geom_bar(stat = "identity") + 
    xlab("Position in motif\n-NN A NN-") +
    ylab("") +
    facet_grid(Exp ~ pattern, labeller = label_both)
```

## Prediction

We evaluate the factorization on miCLIP data from 3 experiments.

```{r}
score_matrix <- select(data_matrix, starts_with("WT_")) %>% 
  as.matrix()
score_matrix <- score_matrix %*% t(h)[colnames(score_matrix), ]
colnames(score_matrix) <- paste0("NMF", 1:nrow(h))

score_matrix <- cbind(score_matrix, data_matrix[, c("region", "motif", "DRACH")])
rownames(score_matrix) <- score_matrix$region
```

## Evaluation

```{r}
# combine score and miCLIP data
data <- merge(score_matrix, miclip[, c("region", "overlap")], by = "region", sort = TRUE)

data$clip <- if_else(data$overlap == "Boulias,Koertel,Koh", "CLIP", "No Clip")

table(data$clip)
```

### Empirical distribution

Plot empirical distribution of scores for each pattern

```{r}
tidyr::gather(data, feature, score, starts_with("NMF")) %>%
  ggplot(aes(x = score, color = clip)) +
    stat_ecdf() +
    theme_bw() +  
    ylab("") +
    scale_color_discrete(name = "") + 
    theme(
      axis.title.x = element_text(size = rel(2)),
      axis.title.y = element_text(size = rel(2)),
      axis.text = element_text(size = rel(1.5))
    ) + 
    facet_wrap(~ feature)
```

### Plot positive predictive value

```{r,warning=FALSE,message=FALSE}
roc_values <- lapply(select(data, starts_with("NMF")), function(x) { 
    roc(data$clip, x)
  }
) %>%
  lapply(function(x) { 
    coordinates <- coords(x, x = "all", input = "threshold", ret = c("threshold", "ppv", "tpr", "tp", "tn", "fp", "fn"))
    coordinates$sum <- log2(coordinates$tp + coordinates$fp)
    coordinates$ppv <- coordinates$ppv * 20
    
    return(coordinates)
  }
) %>%
  dplyr::bind_rows(.id = "feature")

# plot
ggplot(roc_values, aes(x = threshold)) +
  geom_line(aes(y = sum), size = 2, color = "#009E73") +
  geom_line(aes(y = ppv), size = 2, color = "#D55E00") +
  scale_y_continuous(# Features of the first axis
    name = "Log2(#predictions)",
    # Add a second axis and specify its features
    sec.axis = sec_axis( ~ . * 5, name = "Positive Predictive Value")
  ) +  
  scale_x_continuous(name = "Cutoff") + 
  theme_bw() + 
  theme(
    axis.title.x = element_text(size = rel(2)),
    axis.title.y = element_text(color = "#009E73", size = rel(2)),
    axis.title.y.right = element_text(color = "#D55E00", size = rel(0.9)),
    axis.text = element_text(size = rel(1.5))
  ) + 
  facet_wrap(~ feature)
```

# References

